<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <!-- 支持中文 -->
  <title>YuLab Website</title>
  <link rel="stylesheet" href="css/style.css" />
  <link rel="shortcut icon" href="images/logo.jpg" />
</head>

<body>
  <div class="header">
    <div class="logo">
      <h1>Welcome to YuLab!</h1>
    </div>
    <div class="nav">
      <a href="index.html">Home</a>
      <a href="#research">Research</a>
      <a href="#publications">Publications</a>
      <a href="#team">Team</a>
      <a href="#contact">Contact</a>
    </div>
  </div>

  <div class="banner">
    <video src="video/background1.mp4" autoplay muted loop class="video"></video>
  </div>
  
  <!--标题1-->
  <div class="title" id="research">
    <div class="line"></div>
    <h3>Research</h3>
    <div class="line"></div>
  </div>
  <!--research-->
  <div class="research">
    <div class="research-img">
      <img src="images/self-photo.jpg" alt="" />
    </div>
    <div class="research-text">
      <p>2013，博士, 美国肯塔基大学电子信息工程系，Electrical Engineering,
        University of Kentucky, USA</p>
      <p>2007，硕士, 通信与信息系统, 北京交通大学</p>
      <p>2005，学士, 通信工程, 北京交通大学</p>
      <h2>Our research topics mainly involve:</h2>
      <p>· Multichannel Signal Processing</p>
      <p>· Microphone Array Signal Processing</p>
      <p>· IoT Sensor Network</p>
      <a href="http://eie.bjtu.edu.cn/WebHtml/szdw/0406" target="_blank">Click to know more about Professor Yu</a>
      <br />
      <a href="http://eie.bjtu.edu.cn/" target="_blank">Click to view Team Introduction</a>
    </div>
  </div>

  <!--标题2-->
  <div class="title" id="publications">
    <div class="line"></div>
    <h3>Paper Publications</h3>
    <div class="line"></div>
  </div>
  <!--Publications-->
  <div class="publication">
    <!-- 第一篇 -->
    <div class="title1">
      <p >
        Spatial-Tempora Graph Convolution Network for Multichannel Speech Enhancement, ICASSP 2022
      </p>
    </div>
    <div class="abstract1">
      <p>Abstract: Spatial dependency related to distributed microphone positions
        is essential for multichannel speech enhancement task. It is still
        challenging due to lack of accurate array positions and complex
        spatial-temporal relations of multichannel noisy signals. This paper
        proposes a spatial-temporal graph convolutional network composed of
        cascaded spatial-temporal (ST) modules with channel fusion. Without any
        prior information of array and acoustic scene, a graph convolution block
        is designed with learnable adjacency matrix to capture the spatial
        dependency of pairwise channels. Then, it is embedded with time-frequency
        convolution block as the ST module to fuse the multi-dimensional
        correlation features for target speech estimation. Furthermore, a novel
        weighted loss function based on speech intelligibility index (SII) is
        proposed to assign more attention for the important bands of human
        understanding during network training. Our framework is demonstrated to
        achieve over 11% performance improvement on PESQ and intelligibility
        against prior state-of-the-art approaches in multi-scene speech
        enhancement experiments.
      </p>
      <br>
      <a href="http://ahuei.github.io/stgcsen" target="_blank">Go to wave files</a>
      
    </div>

    <!-- 第二篇 -->
    <div class="title1">
      <p >Attention-based Feature-aware Adversarial Learning for Speech Enhancement, submitted to Interspeech 2022</p>
    </div>
    <div class="abstract1">
      <p>Abstract: need to be updated</p>
      <br/>
      <a href="http://ahuei.github.io/stgcsen" target="_blank">Go to wave file1</a>
    </div>

    <!-- 第三篇 -->
    <div class="title1">
      <p > Feature-Aware Adversarial Learning With Spatial-Temporal Graph Convolution Network</p>
    </div>
    <div class="abstract1">
      <p> Abstract: need to be updated</p>
      <br/>
      <a href="https://yangchia.github.io" target="_blank">Go to wave file2</a>
    </div>

    <!-- 第四篇 -->
    <div class="title1">
      <p >Dyanmic Multidimensional Spatial-Temporal Graph Convolutional Network for Scene-Adaptive Speech Enhancement</p>
    </div>
    <div class="abstract1">
      <p>Abstract: need to be updated </p>
      <!-- <br/> -->
      <a href=" https://yulabs2.github.io" target="_blank">Go to wave file3</a> 
    </div>

    <div class="research-video">
      <h1 align="center">Achievements</h1>
      <p align="center">
        <video width="640" height="480" controls="controls" src="./video/doggy.mp4"></video>
      </p>
      <br />
      <p align="center" style="color: grey">xxxxx研究成果示例</p>
    </div>
  </div>

  <!--标题3-->
  <div class="title" id="team">
    <div class="line"></div>
    <h3>Team</h3>
    <div class="line"></div>
  </div>
  <div class="team">
    <span>张三</span>
    <span>李四</span>
    <span>王五</span>
    <span>赵六</span>
    <span>钱多多</span>
  </div>
  <!--标题4-->
  <div class="title" id="contact">
    <div class="line"></div>
    <h3>Contact Info</h3>
    <div class="line"></div>
  </div>
  <div class="contact">
    <p>If any question, feel free to contact jjyu@bjtu.edu.cn
      <br />
      Jekyll Themes
      <br />
      Your Pages site will use the layout and styles from the Jekyll theme you have selected in your repository
      settings. The name of this theme is saved in the Jekyll _config.yml configuration file.
      <br />
      For more details see Basic writing and formatting syntax.
    </p>
  </div>
  <div class="footer">
    <p>© Copyright to YuLab. All Rights Reserved.</p>
  </div>
</body>

</html>